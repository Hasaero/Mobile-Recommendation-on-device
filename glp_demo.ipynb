{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Life Planner Demo\n",
    "\n",
    "This notebook demonstrates the Galaxy Life Planner system, now using a Pohang daily routine with local POIs as the working example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added c:\\Users\\7info\\Desktop\\ÏÇºÏÑ± Í≥ºÏ†ú\\GLP_demo\\src to Python path\n",
      "Current working directory: c:\\Users\\7info\\Desktop\\ÏÇºÏÑ± Í≥ºÏ†ú\\GLP_demo\n"
     ]
    }
   ],
   "source": [
    "# Change to the src directory to access the glp_demo module\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src directory to Python path\n",
    "src_path = os.path.join(os.getcwd(), 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "print(f\"Added {src_path} to Python path\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction Planner Order -> fetch_routine_model, query_personal_graph, query_common_graph, rank_candidates\n",
      "--- Recommendations ---\n",
      "Fit365 Gym: score=0.646\n",
      "  reasoning={'routine': 0.0, 'personal': 1.0, 'intent': 1.0, 'distance': 0.9629350244519002}\n",
      "  message=How about Fit365 Gym (gym)? aligns with recent visits / fits the current app signals / close to your current location.\n",
      "\n",
      "Hanok Kitchen: score=0.539\n",
      "  reasoning={'routine': 0.0, 'personal': 1.0, 'intent': 0.6274509803921569, 'distance': 0.8236466356484318}\n",
      "  message=How about Hanok Kitchen (korean_restaurant)? aligns with recent visits / fits the current app signals / close to your current location.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import and run the GLP demo\n",
    "from glp_demo import demo\n",
    "\n",
    "# Run the demo\n",
    "demo.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Results\n",
    "\n",
    "The demo shows:\n",
    "1. **Instruction Planner Order**: The sequence of operations the system performs\n",
    "2. **Recommendations**: Scored candidates with detailed reasoning\n",
    "3. **Natural Language Explanations**: Human-readable descriptions of why each place was recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot LLM Scoring (Optional)\n",
    "\n",
    "Use the `ZeroShotLLMScorer` to blend an open-source text generation model into the recommendation engine.\n",
    "The snippet below defaults to a lightweight chat checkpoint; switch to any model available in your local Hugging Face cache.\n",
    "\n",
    "- Explanations now come in English with a concise reason summary.\n",
    "- Install `transformers`, `accelerate`, and download the model locally; this cell requests GPU execution (`device_map=\"cuda\"`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Optional: integrate an open-source LLM into zero-shot scoring\nfrom datetime import datetime\n\nimport importlib\n\nfrom glp_demo.app_signals import infer_intent_signals\nfrom glp_demo.ckg import CommonKnowledgeGraph\nfrom glp_demo.demo_data import create_sample_events, create_sample_pois\nfrom glp_demo.pkg import PersonalKnowledgeGraph\nfrom glp_demo.process_mining import build_routine_model\nimport glp_demo.llm as llm_module\nimport glp_demo.recommendation as rec_module\n\n# Reload to pick up the latest implementations if modules were imported earlier\nZeroShotLLMScorer = getattr(importlib.reload(llm_module), \"ZeroShotLLMScorer\")\nExplanationGenerator = getattr(importlib.reload(llm_module), \"ExplanationGenerator\")\nRecommendationEngine = getattr(importlib.reload(rec_module), \"RecommendationEngine\")\n\nevents = create_sample_events()\nroutine = build_routine_model(events)\npkg = PersonalKnowledgeGraph()\npkg.ingest_events(events)\npkg.link_routine(routine)\nckg = CommonKnowledgeGraph(create_sample_pois())\nreference_time = datetime(2025, 9, 26, 18, 30)\nintents = infer_intent_signals(events, reference_time)\n\ntry:\n    scorer = ZeroShotLLMScorer(\n        model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n        device_map=\"cuda\",\n    )\nexcept RuntimeError as exc:\n    print(f\"[WARN] zero-shot scorer disabled -> {exc}\")\n    scorer = None\n\ntry:\n    explanation_generator = ExplanationGenerator(\n        device_map=\"cuda\",\n    )\nexcept RuntimeError as exc:\n    print(f\"[WARN] explanation LLM disabled -> {exc}\")\n    explanation_generator = None\n\nengine = RecommendationEngine(routine, pkg, ckg, zero_shot_scorer=scorer)\nrecommendations = engine.recommend(\n    latitude=36.0539,\n    longitude=129.3745,\n    reference_time=reference_time,\n    intents=intents,\n    radius_km=3.0,\n    limit=3,\n)\n\nfor item in recommendations:\n    poi = item.candidate.poi\n    if explanation_generator is not None:\n        message = explanation_generator.build_message(item)\n    else:\n        message = f\"Fallback explanation -> {item.candidate.reasoning_tokens}\"\n    print(f\"{poi.name} -> score={item.candidate.score:.3f}, reasoning={item.candidate.reasoning_tokens}\")\n    print(f\"  message={message}\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Recommendation Demo\n",
    "\n",
    "This section demonstrates how the system handles **zero-shot POIs** (places the user has never visited before).\n",
    "\n",
    "### Key Features:\n",
    "- **Context-aware scoring**: LLM analyzes user intent, time, and location\n",
    "- **Semantic understanding**: Matches POI categories with user intentions\n",
    "- **Exploration boost**: Encourages discovery of new relevant places\n",
    "\n",
    "### Example Scenario:\n",
    "User has strong exercise intent (fitness app usage) but encounters a new gym they have never visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Recommendation with Mock LLM Scorer\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "from glp_demo.demo_data import create_sample_events, create_sample_pois\n",
    "from glp_demo.pkg import PersonalKnowledgeGraph\n",
    "from glp_demo.ckg import CommonKnowledgeGraph\n",
    "from glp_demo.process_mining import build_routine_model\n",
    "from glp_demo.app_signals import infer_intent_signals\n",
    "import glp_demo.recommendation as rec_module\n",
    "\n",
    "# Reload to get the latest POI data (including new Premium Fitness Club)\n",
    "RecommendationEngine = getattr(importlib.reload(rec_module), \"RecommendationEngine\")\n",
    "\n",
    "# Mock Zero-Shot LLM Scorer\n",
    "class MockZeroShotScorer:\n",
    "    \"\"\"Simulates LLM-based scoring for zero-shot POIs based on context understanding\"\"\"\n",
    "    \n",
    "    def score(self, context, poi_features):\n",
    "        scores = {}\n",
    "        intent_scores = context.get('intent_scores', {})\n",
    "        time_slot = context.get('time_slot', 'unknown')\n",
    "        \n",
    "        for feature in poi_features:\n",
    "            poi_id = feature['poi_id']\n",
    "            category = feature['category']\n",
    "            \n",
    "            # Context-aware scoring logic\n",
    "            score = 0.1  # base score\n",
    "            \n",
    "            # Strong intent-category matching\n",
    "            if category == 'gym' and intent_scores.get('exercise', 0) > 0.8:\n",
    "                score = 0.9  # Perfect match: exercise intent + gym\n",
    "            elif category == 'italian_restaurant' and intent_scores.get('meal', 0) > 0.5:\n",
    "                score = 0.7  # Good match: meal intent + restaurant\n",
    "            elif category == 'coffee_shop' and intent_scores.get('social', 0) > 0.4:\n",
    "                score = 0.6  # Social intent + cafe\n",
    "            elif category == 'convenience_store':\n",
    "                score = 0.3  # Always somewhat useful\n",
    "            \n",
    "            # Time-based adjustments\n",
    "            if time_slot == 'evening' and category == 'gym':\n",
    "                score += 0.1  # Evening gym bonus\n",
    "            \n",
    "            scores[poi_id] = min(1.0, score)  # Cap at 1.0\n",
    "        \n",
    "        return scores\n",
    "\n",
    "# Setup data and models\n",
    "events = create_sample_events()\n",
    "routine = build_routine_model(events)\n",
    "pkg = PersonalKnowledgeGraph()\n",
    "pkg.ingest_events(events)\n",
    "pkg.link_routine(routine)\n",
    "ckg = CommonKnowledgeGraph(create_sample_pois())\n",
    "\n",
    "reference_time = datetime(2025, 9, 26, 18, 30)  # Evening time\n",
    "intents = infer_intent_signals(events, reference_time)\n",
    "\n",
    "print(\"=== Current User Intents ===\")\n",
    "for intent in intents[:3]:  # Show top 3\n",
    "    print(f\"{intent.intent}: {intent.score:.3f}\")\n",
    "\n",
    "# Create recommendation engine with zero-shot scorer\n",
    "zero_shot_scorer = MockZeroShotScorer()\n",
    "engine = RecommendationEngine(routine, pkg, ckg, zero_shot_scorer=zero_shot_scorer)\n",
    "\n",
    "recommendations = engine.recommend(\n",
    "    latitude=36.0539,\n",
    "    longitude=129.3745,\n",
    "    reference_time=reference_time,\n",
    "    intents=intents,\n",
    "    radius_km=3.0,\n",
    "    limit=5,\n",
    ")\n",
    "\n",
    "print(\"\n=== Recommendations (Including Zero-Shot) ===\")\n",
    "for i, item in enumerate(recommendations, 1):\n",
    "    poi = item.candidate.poi\n",
    "    reasoning = item.candidate.reasoning_tokens\n",
    "    visit_count = pkg.place_visit_counts.get(poi.poi_id, 0)\n",
    "    \n",
    "    # Determine if this is a zero-shot POI\n",
    "    is_zero_shot = visit_count == 0\n",
    "    status = \"üÜï ZERO-SHOT\" if is_zero_shot else f\"üìç Visited {visit_count}x\"\n",
    "    \n",
    "    print(f\"{i}. {poi.name} ({status})\")\n",
    "    print(f\"   Final Score: {item.candidate.score:.3f}\")\n",
    "    print(f\"   Category: {poi.category}\")\n",
    "    \n",
    "    # Show score breakdown\n",
    "    print(f\"   Score Breakdown:\")\n",
    "    for signal, score in reasoning.items():\n",
    "        if signal == 'llm':\n",
    "            print(f\"     ü§ñ LLM Bonus: {score:.3f} (zero-shot only)\")\n",
    "        else:\n",
    "            print(f\"     {signal}: {score:.3f}\")\n",
    "    \n",
    "    if is_zero_shot:\n",
    "        print(f\"   üí° Why recommended: High {list(intents)[0].intent} intent matches {poi.category}\")\n",
    "    \n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}